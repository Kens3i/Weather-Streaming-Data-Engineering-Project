{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc78d536-a5de-4598-8304-fdff0634e743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending Test Event from dbw to Event Hub without secret (directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c385ceb-3550-4209-b326-62e6a84d167a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Sent event: {&#34;event_id&#34;: 1111, &#34;event_name&#34;: &#34;Test Event&#34;}\n",
       "Event Hub producer closed.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Sent event: {&#34;event_id&#34;: 1111, &#34;event_name&#34;: &#34;Test Event&#34;}\nEvent Hub producer closed.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary classes from the Azure Event Hubs SDK\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Event Hub Configuration\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Replace with your Event Hub namespace connection string, Event hub -> shared access policies -> open our databrick policy -> copy connection string primary key \n",
    "EVENT_HUB_CONNECTION_STRING = \"Endpoint=sb://eventh-weather-streaming-namespace.servicebus.windows.net/;SharedAccessKeyName=for-databricks;SharedAccessKey=viPgu7KNfVILLyz+A7X2vP0uI1HBbXnEN+AEhI4oOqg=;EntityPath=weather-streaming-event-hub\"\n",
    "\n",
    "# Replace with your Event Hub name (the specific hub within the namespace)\n",
    "EVENT_HUB_NAME = \"weather-streaming-event-hub\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Initialize the Event Hub Producer\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Create a producer client to send messages to the Event Hub, responsible for sending the events towards the event hub\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "    conn_str=EVENT_HUB_CONNECTION_STRING,\n",
    "    eventhub_name=EVENT_HUB_NAME\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Define a Function to Send Events\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def send_event(event: dict):\n",
    "    \"\"\"\n",
    "    Sends a single JSON-serializable event to Azure Event Hub.\n",
    "\n",
    "    Parameters:\n",
    "        event (dict): The event payload to send.\n",
    "    \"\"\"\n",
    "    # Create a new batch. Batching helps optimize throughput.\n",
    "    event_data_batch = producer.create_batch()\n",
    "    \n",
    "    # Serialize the event dict to a JSON string and wrap it in EventData\n",
    "    event_json = json.dumps(event)\n",
    "    event_data = EventData(event_json)\n",
    "\n",
    "    \"\"\"\n",
    "    event = {\n",
    "    \"event_id\": 42,\n",
    "    \"event_name\": \"temperature_reading\",\n",
    "    \"value_celsius\": 23.7,\n",
    "    \"timestamp\": \"2025-05-27T12:34:56Z\"\n",
    "    }\n",
    "    \n",
    "    event_json = json.dumps(event)\n",
    "    print(event_json)\n",
    "    # Output:\n",
    "    # {\"event_id\": 42, \"event_name\": \"temperature_reading\", \"value_celsius\": 23.7, \"timestamp\": \"2025-05-27T12:34:56Z\"}\n",
    "\n",
    "    # 3) Wrap that JSON string in an EventData object:\n",
    "    event_data = EventData(event_json)\n",
    "\n",
    "    # Internally, EventData stores the JSON as its body (in bytes). \n",
    "    # You can inspect it in Databricks like so:\n",
    "    print(event_data.body_as_str(encoding='UTF-8'))\n",
    "    # Output:\n",
    "    # {\"event_id\": 42, \"event_name\": \"temperature_reading\", \"value_celsius\": 23.7, \"timestamp\": \"2025-05-27T12:34:56Z\"}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add this EventData to the batch\n",
    "    event_data_batch.add(event_data)\n",
    "    \n",
    "    # Send the batch to the Event Hub\n",
    "    producer.send_batch(event_data_batch)\n",
    "    print(f\"Sent event: {event_json}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4. Create a Sample Event and Send It\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example payload — can be any JSON-serializable content\n",
    "    sample_event = {\n",
    "        \"event_id\": 1111,\n",
    "        \"event_name\": \"Test Event\"\n",
    "    }\n",
    "    \n",
    "    # Send the sample event to validate connectivity\n",
    "    send_event(sample_event)\n",
    "    \n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    # 5. Clean Up\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    # Close the producer to free up resources\n",
    "    producer.close()\n",
    "    print(\"Event Hub producer closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "365dc9d3-6ea0-44f6-bc15-2cbdab1759aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending Test Event from dbw to Event Hub with secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "988e5c48-002e-47be-8616-eb4a2f840776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Sent event: {&#34;event_id&#34;: 2222, &#34;event_name&#34;: &#34;Secret scope test&#34;}\n",
       "Event Hub producer closed.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Sent event: {&#34;event_id&#34;: 2222, &#34;event_name&#34;: &#34;Secret scope test&#34;}\nEvent Hub producer closed.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary classes from the Azure Event Hubs SDK\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Event Hub Configuration\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "# Retrieve Connection String Securely from Key Vault\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# This assumes you've already created a Databricks secret scope named \"key-vault-secret-scope\"\n",
    "# and stored your Event Hub connection string under the secret name \"eventhub-connection-string-secret\".\n",
    "eventhub_connection_string = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\",\n",
    "    key=\"eventhub-connection-string-secret\"\n",
    ")\n",
    "\n",
    "# Replace with your Event Hub name (the specific hub within the namespace)\n",
    "EVENT_HUB_NAME = \"weather-streaming-event-hub\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Initialize the Event Hub Producer\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Create a producer client to send messages to the Event Hub, responsidble for sending the vents towards the event hub\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "    conn_str=eventhub_connection_string,\n",
    "    eventhub_name=EVENT_HUB_NAME\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Define a Function to Send Events\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def send_event(event: dict):\n",
    "    \"\"\"\n",
    "    Sends a single JSON-serializable event to Azure Event Hub.\n",
    "\n",
    "    Parameters:\n",
    "        event (dict): The event payload to send.\n",
    "    \"\"\"\n",
    "    # Create a new batch. Batching helps optimize throughput.\n",
    "    event_data_batch = producer.create_batch()\n",
    "    \n",
    "    # Serialize the event dict to a JSON string and wrap it in EventData\n",
    "    event_json = json.dumps(event)\n",
    "    event_data = EventData(event_json)\n",
    "    \n",
    "    # Add this EventData to the batch\n",
    "    event_data_batch.add(event_data)\n",
    "    \n",
    "    # Send the batch to the Event Hub\n",
    "    producer.send_batch(event_data_batch)\n",
    "    print(f\"Sent event: {event_json}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4. Create a Sample Event and Send It\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example payload — can be any JSON-serializable content\n",
    "    sample_event = {\n",
    "        \"event_id\": 2222,\n",
    "        \"event_name\": \"Secret scope test\"\n",
    "    }\n",
    "    \n",
    "    # Send the sample event to validate connectivity\n",
    "    send_event(sample_event)\n",
    "    \n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    # 5. Clean Up\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    # Close the producer to free up resources\n",
    "    producer.close()\n",
    "    print(\"Event Hub producer closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d55fe3b4-bb68-4b92-ad56-3bac1fa17c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## API Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4c021e-3cdc-48d2-8429-c8ea586a3d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Current Weather:\n",
       "{\n",
       "  &#34;location&#34;: {\n",
       "    &#34;name&#34;: &#34;Kolkata&#34;,\n",
       "    &#34;region&#34;: &#34;West Bengal&#34;,\n",
       "    &#34;country&#34;: &#34;India&#34;,\n",
       "    &#34;lat&#34;: 22.5697,\n",
       "    &#34;lon&#34;: 88.3697,\n",
       "    &#34;tz_id&#34;: &#34;Asia/Kolkata&#34;,\n",
       "    &#34;localtime_epoch&#34;: 1748207147,\n",
       "    &#34;localtime&#34;: &#34;2025-05-26 02:35&#34;\n",
       "  },\n",
       "  &#34;current&#34;: {\n",
       "    &#34;last_updated_epoch&#34;: 1748206800,\n",
       "    &#34;last_updated&#34;: &#34;2025-05-26 02:30&#34;,\n",
       "    &#34;temp_c&#34;: 28.3,\n",
       "    &#34;temp_f&#34;: 82.9,\n",
       "    &#34;is_day&#34;: 0,\n",
       "    &#34;condition&#34;: {\n",
       "      &#34;text&#34;: &#34;Mist&#34;,\n",
       "      &#34;icon&#34;: &#34;//cdn.weatherapi.com/weather/64x64/night/143.png&#34;,\n",
       "      &#34;code&#34;: 1030\n",
       "    },\n",
       "    &#34;wind_mph&#34;: 4.9,\n",
       "    &#34;wind_kph&#34;: 7.9,\n",
       "    &#34;wind_degree&#34;: 128,\n",
       "    &#34;wind_dir&#34;: &#34;SE&#34;,\n",
       "    &#34;pressure_mb&#34;: 1002.0,\n",
       "    &#34;pressure_in&#34;: 29.59,\n",
       "    &#34;precip_mm&#34;: 0.0,\n",
       "    &#34;precip_in&#34;: 0.0,\n",
       "    &#34;humidity&#34;: 94,\n",
       "    &#34;cloud&#34;: 75,\n",
       "    &#34;feelslike_c&#34;: 33.1,\n",
       "    &#34;feelslike_f&#34;: 91.6,\n",
       "    &#34;windchill_c&#34;: 28.4,\n",
       "    &#34;windchill_f&#34;: 83.2,\n",
       "    &#34;heatindex_c&#34;: 33.4,\n",
       "    &#34;heatindex_f&#34;: 92.1,\n",
       "    &#34;dewpoint_c&#34;: 24.8,\n",
       "    &#34;dewpoint_f&#34;: 76.6,\n",
       "    &#34;vis_km&#34;: 2.4,\n",
       "    &#34;vis_miles&#34;: 1.0,\n",
       "    &#34;uv&#34;: 0.0,\n",
       "    &#34;gust_mph&#34;: 7.7,\n",
       "    &#34;gust_kph&#34;: 12.4\n",
       "  }\n",
       "}\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Current Weather:\n{\n  &#34;location&#34;: {\n    &#34;name&#34;: &#34;Kolkata&#34;,\n    &#34;region&#34;: &#34;West Bengal&#34;,\n    &#34;country&#34;: &#34;India&#34;,\n    &#34;lat&#34;: 22.5697,\n    &#34;lon&#34;: 88.3697,\n    &#34;tz_id&#34;: &#34;Asia/Kolkata&#34;,\n    &#34;localtime_epoch&#34;: 1748207147,\n    &#34;localtime&#34;: &#34;2025-05-26 02:35&#34;\n  },\n  &#34;current&#34;: {\n    &#34;last_updated_epoch&#34;: 1748206800,\n    &#34;last_updated&#34;: &#34;2025-05-26 02:30&#34;,\n    &#34;temp_c&#34;: 28.3,\n    &#34;temp_f&#34;: 82.9,\n    &#34;is_day&#34;: 0,\n    &#34;condition&#34;: {\n      &#34;text&#34;: &#34;Mist&#34;,\n      &#34;icon&#34;: &#34;//cdn.weatherapi.com/weather/64x64/night/143.png&#34;,\n      &#34;code&#34;: 1030\n    },\n    &#34;wind_mph&#34;: 4.9,\n    &#34;wind_kph&#34;: 7.9,\n    &#34;wind_degree&#34;: 128,\n    &#34;wind_dir&#34;: &#34;SE&#34;,\n    &#34;pressure_mb&#34;: 1002.0,\n    &#34;pressure_in&#34;: 29.59,\n    &#34;precip_mm&#34;: 0.0,\n    &#34;precip_in&#34;: 0.0,\n    &#34;humidity&#34;: 94,\n    &#34;cloud&#34;: 75,\n    &#34;feelslike_c&#34;: 33.1,\n    &#34;feelslike_f&#34;: 91.6,\n    &#34;windchill_c&#34;: 28.4,\n    &#34;windchill_f&#34;: 83.2,\n    &#34;heatindex_c&#34;: 33.4,\n    &#34;heatindex_f&#34;: 92.1,\n    &#34;dewpoint_c&#34;: 24.8,\n    &#34;dewpoint_f&#34;: 76.6,\n    &#34;vis_km&#34;: 2.4,\n    &#34;vis_miles&#34;: 1.0,\n    &#34;uv&#34;: 0.0,\n    &#34;gust_mph&#34;: 7.7,\n    &#34;gust_kph&#34;: 12.4\n  }\n}\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Imports\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "import requests    # For making HTTP requests to the Weather API\n",
    "import json        # For parsing and pretty-printing JSON responses\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Retrieve API Key from Azure Key Vault\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# This assumes you have a Databricks secret scope named \"key-vault-scope\"\n",
    "# and that you've stored your Weather API key under the secret name \"weather-api-key\" in Azure key vault.\n",
    "weather_api_key = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\",\n",
    "    key=\"weather-api-key\"\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Define the API Endpoint and Parameters\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "location = \"Kolkata\"                   # City for which you want the weather\n",
    "base_url = \"http://api.weatherapi.com/v1\"\n",
    "current_url = f\"{base_url}/current.json\"\n",
    "\n",
    "# The Weather API expects two query parameters:\n",
    "#  - 'key': your API key\n",
    "#  - 'q':  the location string (city name, coordinates, ZIP, etc.)\n",
    "params = {\n",
    "    \"key\": weather_api_key,\n",
    "    \"q\": location\n",
    "}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4. Make the HTTP GET Request\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "response = requests.get(current_url, params=params)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5. Handle the Response\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if response.status_code == 200:\n",
    "    # 200 means Success: parse the JSON payload\n",
    "    current_weather = response.json()\n",
    "    \n",
    "    # Pretty-print the weather data\n",
    "    print(\"Current Weather:\")\n",
    "    print(json.dumps(current_weather, indent=2))\n",
    "else:\n",
    "    # Something went wrong: print status code and error text\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a10ec14-d18a-46a6-b778-d7b2c30fb206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Code for getting weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbd314d4-8c1c-4633-ac5e-87a6d2160253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Weather Data:\n",
       "{\n",
       "   &#34;name&#34;: &#34;Kolkata&#34;,\n",
       "   &#34;region&#34;: &#34;West Bengal&#34;,\n",
       "   &#34;country&#34;: &#34;India&#34;,\n",
       "   &#34;lat&#34;: 22.5697,\n",
       "   &#34;lon&#34;: 88.3697,\n",
       "   &#34;localtime&#34;: &#34;2025-05-27 00:26&#34;,\n",
       "   &#34;temp_c&#34;: 27.1,\n",
       "   &#34;condition_text&#34;: &#34;Mist&#34;,\n",
       "   &#34;wind_kph&#34;: 12.2,\n",
       "   &#34;humidity&#34;: 89,\n",
       "   &#34;air_quality&#34;: {\n",
       "      &#34;co&#34;: 688.2,\n",
       "      &#34;no2&#34;: 43.66,\n",
       "      &#34;o3&#34;: 35.0,\n",
       "      &#34;so2&#34;: 21.09,\n",
       "      &#34;pm2_5&#34;: 58.275,\n",
       "      &#34;pm10&#34;: 59.57,\n",
       "      &#34;us-epa-index&#34;: 3,\n",
       "      &#34;gb-defra-index&#34;: 7\n",
       "   },\n",
       "   &#34;alerts&#34;: [],\n",
       "   &#34;forecast&#34;: [\n",
       "      {\n",
       "         &#34;date&#34;: &#34;2025-05-27&#34;,\n",
       "         &#34;maxtemp_c&#34;: 34.7,\n",
       "         &#34;mintemp_c&#34;: 27.1,\n",
       "         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n",
       "      },\n",
       "      {\n",
       "         &#34;date&#34;: &#34;2025-05-28&#34;,\n",
       "         &#34;maxtemp_c&#34;: 33.6,\n",
       "         &#34;mintemp_c&#34;: 27.7,\n",
       "         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n",
       "      },\n",
       "      {\n",
       "         &#34;date&#34;: &#34;2025-05-29&#34;,\n",
       "         &#34;maxtemp_c&#34;: 32.4,\n",
       "         &#34;mintemp_c&#34;: 26.6,\n",
       "         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n",
       "      }\n",
       "   ]\n",
       "}\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Weather Data:\n{\n   &#34;name&#34;: &#34;Kolkata&#34;,\n   &#34;region&#34;: &#34;West Bengal&#34;,\n   &#34;country&#34;: &#34;India&#34;,\n   &#34;lat&#34;: 22.5697,\n   &#34;lon&#34;: 88.3697,\n   &#34;localtime&#34;: &#34;2025-05-27 00:26&#34;,\n   &#34;temp_c&#34;: 27.1,\n   &#34;condition_text&#34;: &#34;Mist&#34;,\n   &#34;wind_kph&#34;: 12.2,\n   &#34;humidity&#34;: 89,\n   &#34;air_quality&#34;: {\n      &#34;co&#34;: 688.2,\n      &#34;no2&#34;: 43.66,\n      &#34;o3&#34;: 35.0,\n      &#34;so2&#34;: 21.09,\n      &#34;pm2_5&#34;: 58.275,\n      &#34;pm10&#34;: 59.57,\n      &#34;us-epa-index&#34;: 3,\n      &#34;gb-defra-index&#34;: 7\n   },\n   &#34;alerts&#34;: [],\n   &#34;forecast&#34;: [\n      {\n         &#34;date&#34;: &#34;2025-05-27&#34;,\n         &#34;maxtemp_c&#34;: 34.7,\n         &#34;mintemp_c&#34;: 27.1,\n         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n      },\n      {\n         &#34;date&#34;: &#34;2025-05-28&#34;,\n         &#34;maxtemp_c&#34;: 33.6,\n         &#34;mintemp_c&#34;: 27.7,\n         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n      },\n      {\n         &#34;date&#34;: &#34;2025-05-29&#34;,\n         &#34;maxtemp_c&#34;: 32.4,\n         &#34;mintemp_c&#34;: 26.6,\n         &#34;condition&#34;: &#34;Patchy rain nearby&#34;\n      }\n   ]\n}\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # COMMAND ----------\n",
    "# ### Complete code for getting weather data\n",
    "\n",
    "# # COMMAND ----------\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0) Imports for full-featured API functions\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Helper: Uniform response handling\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def handle_response(response):\n",
    "    \"\"\"\n",
    "    Returns parsed JSON on HTTP 200, otherwise an error message.\n",
    "    \"\"\"\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return {\"error\": f\"{response.status_code}: {response.text}\"}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Fetch current weather + AQI\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    url = f\"{base_url}current.json\"\n",
    "    params = {\"key\": api_key, \"q\": location, \"aqi\": \"yes\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Fetch multi-day forecast\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    url = f\"{base_url}/forecast.json\"\n",
    "    params = {\"key\": api_key, \"q\": location, \"days\": days}\n",
    "    response = requests.get(url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Fetch weather alerts\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    url = f\"{base_url}/alerts.json\"\n",
    "    params = {\"key\": api_key, \"q\": location, \"alerts\": \"yes\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Flatten & merge disparate API responses\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    \"\"\"\n",
    "    Extracts key fields from each response and merges them into one flat dict.\n",
    "    \"\"\"\n",
    "    # Location & current conditions\n",
    "    loc = current_weather.get(\"location\", {})\n",
    "    curr = current_weather.get(\"current\", {})\n",
    "    cond = curr.get(\"condition\", {})\n",
    "    aqi = curr.get(\"air_quality\", {})\n",
    "    \n",
    "    # Forecast days list and alerts list\n",
    "    forecast_days = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_items = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "    \n",
    "    # Build a single flat record\n",
    "    flattened = {\n",
    "        # Location metadata\n",
    "        \"name\": loc.get(\"name\"),\n",
    "        \"region\": loc.get(\"region\"),\n",
    "        \"country\": loc.get(\"country\"),\n",
    "        \"lat\": loc.get(\"lat\"),\n",
    "        \"lon\": loc.get(\"lon\"),\n",
    "        \"localtime\": loc.get(\"localtime\"),\n",
    "        # Current weather details\n",
    "        \"temp_c\": curr.get(\"temp_c\"),\n",
    "        \"condition_text\": cond.get(\"text\"),\n",
    "        \"wind_kph\": curr.get(\"wind_kph\"),\n",
    "        \"humidity\": curr.get(\"humidity\"),\n",
    "        # Air quality sub-fields\n",
    "        \"air_quality\": {k: aqi.get(k) for k in aqi.keys()},\n",
    "        # Active alerts (if any)\n",
    "        \"alerts\": [\n",
    "            {\n",
    "                \"headline\": a.get(\"headline\"),\n",
    "                \"severity\": a.get(\"severity\"),\n",
    "                \"description\": a.get(\"desc\")\n",
    "            }\n",
    "            for a in alert_items\n",
    "        ],\n",
    "        # 3-day forecast summary\n",
    "        \"forecast\": [\n",
    "            {\n",
    "                \"date\": d.get(\"date\"),\n",
    "                \"maxtemp_c\": d.get(\"day\", {}).get(\"maxtemp_c\"),\n",
    "                \"mintemp_c\": d.get(\"day\", {}).get(\"mintemp_c\"),\n",
    "                \"condition\": d.get(\"day\", {}).get(\"condition\", {}).get(\"text\")\n",
    "            }\n",
    "            for d in forecast_days\n",
    "        ]\n",
    "    }\n",
    "    return flattened\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Main orchestration function\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def fetch_weather_data():\n",
    "    \"\"\"\n",
    "    Retrieves current, forecast, and alert data, merges it,\n",
    "    and prints a single consolidated JSON payload.\n",
    "    \"\"\"\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Kolkata\"\n",
    "    api_key = dbutils.secrets.get(scope=\"key-vault-secret-scope\", key=\"weather-api-key\")\n",
    "    \n",
    "    # 1. Pull raw data\n",
    "    current = get_current_weather(base_url, api_key, location)\n",
    "    forecast = get_forecast_weather(base_url, api_key, location, days=3)\n",
    "    alerts = get_alerts(base_url, api_key, location)\n",
    "    \n",
    "    # 2. Normalize & merge into one record\n",
    "    merged = flatten_data(current, forecast, alerts)\n",
    "    \n",
    "    # 3. Output for inspection or downstream processing\n",
    "    print(\"Weather Data:\")\n",
    "    print(json.dumps(merged, indent=3))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Kick off the pipeline\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "fetch_weather_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5eaf4b1d-bae4-4598-bb93-a723be6e740e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Sending the complete weather data to Event Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5181285-f917-4eec-ac96-1db7f134e678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Combining above 2 code blocks together (Above we have the complete code to get weather data + Script to send data to event hub =  Sending weather data as a single event in event hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeee5369-10ef-41fb-ad96-296411c41561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries for HTTP requests, JSON handling, and Event Hub communication\n",
    "import requests\n",
    "import json\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1. Configure Event Hub connection\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Securely retrieve the Event Hub connection string from Azure Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\",\n",
    "    key=\"eventhub-connection-string-secret\"\n",
    ")\n",
    "\n",
    "# Define the Event Hub name where the event will be published\n",
    "EVENT_HUB_NAME = \"weather-streaming-event-hub\"\n",
    "\n",
    "# Initialize the Event Hub producer client using the secure connection string\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "    conn_str=eventhub_connection_string, \n",
    "    eventhub_name=EVENT_HUB_NAME\n",
    ")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2. Function to send an event (JSON) to Azure Event Hub\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def send_event(event):\n",
    "    # Create a new batch to group events before sending\n",
    "    event_data_batch = producer.create_batch()\n",
    "    \n",
    "    # Convert the event dictionary into a JSON string and wrap it in EventData\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    \n",
    "    # Send the batch to the Event Hub\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3. Helper function to handle HTTP response\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        # Return parsed JSON if request was successful\n",
    "        return response.json()\n",
    "    else:\n",
    "        # Return an error message if request failed\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4. Functions to retrieve weather data from the API\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    # Call the current weather API including air quality info\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {'key': api_key, 'q': location, \"aqi\": 'yes'}\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    # Call the forecast API for specified number of days\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\"key\": api_key, \"q\": location, \"days\": days}\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    # Call the alerts API to check for severe weather\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {'key': api_key, 'q': location, \"alerts\": 'yes'}\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5. Merge and flatten all API responses into a single dict\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    # Safely extract sections from nested API responses\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    # Create a clean, structured event record\n",
    "    flattened_data = {\n",
    "        # Location metadata\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "\n",
    "        # Current weather conditions\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "\n",
    "        # Air quality measurements\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "\n",
    "        # Weather alerts\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "\n",
    "        # 3-day forecast\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return flattened_data\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6. Main function to coordinate all steps\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def fetch_weather_data():\n",
    "    # Base URL of the Weather API\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    \n",
    "    # Desired city\n",
    "    location = \"Kolkata\"\n",
    "\n",
    "    # Get the Weather API key securely from Key Vault\n",
    "    weatherapikey = dbutils.secrets.get(\n",
    "        scope=\"key-vault-secret-scope\", \n",
    "        key=\"weather-api-key\"\n",
    "    )\n",
    "\n",
    "    # Step 1: Call all three API endpoints\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "\n",
    "    # Step 2: Merge into a flat event structure\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "\n",
    "    # Step 3: Send to Event Hub\n",
    "    send_event(merged_data)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 7. Trigger the process\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# This line initiates the full process: fetch → merge → send\n",
    "fetch_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4238ab4d-f2d0-4fe2-9560-773a228582f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The above code only sends one event with the latest weather data hence modifying the code for Spark Structured Streaming Loop (1 sec rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88727601-a2a5-425f-98b4-711673da2636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Imports: Event Hub client, JSON, HTTP requests, and Spark\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from azure.eventhub import EventHubProducerClient, EventData  # Azure SDK for sending events\n",
    "import json                                                    # JSON serialization\n",
    "import requests                                                # REST API calls\n",
    "# Note: Spark is already available in Databricks for streaming\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Secure configuration: retrieve secrets from Key Vault\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "EVENT_HUB_NAME = \"weather-streaming-event-hub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\", \n",
    "    key=\"eventhub-connection-string-secret\"\n",
    ")\n",
    "weatherapikey = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\", \n",
    "    key=\"weather-api-key\"\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Initialize the Event Hub producer client once\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "    conn_str=eventhub_connection_string,\n",
    "    eventhub_name=EVENT_HUB_NAME\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Helper: wrap a dict as JSON and send to Event Hub\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def send_event(event: dict):\n",
    "    batch = producer.create_batch()           # Create a new batch container\n",
    "    batch.add(EventData(json.dumps(event)))   # Serialize dict → JSON → EventData\n",
    "    producer.send_batch(batch)                # Push the batch to the hub\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Helper: unified API response handling\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()                # Return parsed JSON on success\n",
    "    return { \"error\": f\"{response.status_code}: {response.text}\" }\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Weather API calls (current, forecast, alerts)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    url = f\"{base_url}/current.json\"\n",
    "    params = {'key': api_key, 'q': location, 'aqi': 'yes'}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    url = f\"{base_url}/forecast.json\"\n",
    "    params = {'key': api_key, 'q': location, 'days': days}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    url = f\"{base_url}/alerts.json\"\n",
    "    params = {'key': api_key, 'q': location, 'alerts': 'yes'}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Flatten nested API outputs into one simple dict\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def flatten_data(current, forecast, alerts):\n",
    "    loc = current.get(\"location\", {})\n",
    "    cur = current.get(\"current\", {})\n",
    "    cond = cur.get(\"condition\", {})\n",
    "    aqi = cur.get(\"air_quality\", {})\n",
    "    days = forecast.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alerts_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    return {\n",
    "        \"name\":     loc.get(\"name\"),\n",
    "        \"region\":   loc.get(\"region\"),\n",
    "        \"country\":  loc.get(\"country\"),\n",
    "        \"temp_c\":   cur.get(\"temp_c\"),\n",
    "        \"condition\": cond.get(\"text\"),\n",
    "        \"air_quality\": {k: aqi.get(k) for k in aqi},\n",
    "        \"forecast\": [\n",
    "            {\n",
    "                \"date\":       d.get(\"date\"),\n",
    "                \"max_temp\":   d.get(\"day\", {}).get(\"maxtemp_c\"),\n",
    "                \"min_temp\":   d.get(\"day\", {}).get(\"mintemp_c\"),\n",
    "                \"condition\":  d.get(\"day\", {}).get(\"condition\", {}).get(\"text\")\n",
    "            }\n",
    "            for d in days\n",
    "        ],\n",
    "        \"alerts\": [\n",
    "            {\n",
    "                \"headline\":    a.get(\"headline\"),\n",
    "                \"severity\":    a.get(\"severity\"),\n",
    "                \"description\": a.get(\"desc\")\n",
    "            }\n",
    "            for a in alerts_list\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Fetch + flatten all weather data (no sending)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1\"\n",
    "    location = \"Kolkata\"  # or any city\n",
    "    # Call each endpoint\n",
    "    curr    = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast= get_forecast_weather(base_url, weatherapikey, location, days=3)\n",
    "    alrt    = get_alerts(base_url, weatherapikey, location)\n",
    "    # Merge into one record\n",
    "    return flatten_data(curr, forecast, alrt)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 9) Batch processor invoked by Spark Structured Streaming\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def process_batch(batch_df, batch_id):\n",
    "    \"\"\"\n",
    "    Called for each micro-batch of the Spark stream.\n",
    "    We ignore batch_df content (using rate source) and instead\n",
    "    fetch real weather data and send it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = fetch_weather_data()   # Get fresh weather snapshot\n",
    "        send_event(data)              # Publish to Event Hub\n",
    "    except Exception as e:\n",
    "        # Log and rethrow to allow Spark to surface the error\n",
    "        print(f\"Error in batch {batch_id}: {e}\")\n",
    "        raise\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 10) Define a dummy streaming source (rate) for pacing\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "streaming_df = (\n",
    "    spark.readStream\n",
    "         .format(\"rate\")               # Built-in source that generates rows at a fixed rate\n",
    "         .option(\"rowsPerSecond\", 1)   # 1 row per second → trigger one batch per second\n",
    "         .load()\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 11) Hook our processor into the streaming query\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "query = (\n",
    "    streaming_df.writeStream\n",
    "               .foreachBatch(process_batch)   # Call process_batch() each micro-batch\n",
    "               .start()\n",
    ")\n",
    "\n",
    "# Wait forever (or until manually stopped)\n",
    "query.awaitTermination()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 12) Cleanup: close the Event Hub producer when done\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "producer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dd46cf9-0f68-4556-91d8-96ac4cc236ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending data from API to Event hub every 30 Seconds (as the weather data doesn't change every second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "688b0dff-5e4c-49c6-9c6f-83cf08834f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Event sent at 2025-05-26T19:58:55.433828\n",
       "Event sent at 2025-05-26T19:59:25.626022\n",
       "Event sent at 2025-05-26T19:59:55.634495\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Event sent at 2025-05-26T19:58:55.433828\nEvent sent at 2025-05-26T19:59:25.626022\nEvent sent at 2025-05-26T19:59:55.634495\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Imports: Event Hub client, JSON, HTTP, and scheduling utilities\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from azure.eventhub import EventHubProducerClient, EventData  # Azure SDK for sending events\n",
    "import json                                                    # JSON serialization\n",
    "import requests                                                # REST API calls\n",
    "from datetime import datetime, timedelta                       # Time comparison for throttling\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Secure configuration: retrieve secrets from Azure Key Vault\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "EVENT_HUB_NAME = \"weather-streaming-event-hub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\",\n",
    "    key=\"eventhub-connection-string-secret\"                           # Secret storing the Event Hub connection\n",
    ")\n",
    "weather_api_key = dbutils.secrets.get(\n",
    "    scope=\"key-vault-secret-scope\",\n",
    "    key=\"weather-api-key\"                                        # Secret storing the Weather API key\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Initialize a single Event Hub producer client\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "    conn_str=eventhub_connection_string,\n",
    "    eventhub_name=EVENT_HUB_NAME\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Helper: send a Python dict as JSON to Event Hub\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def send_event(event: dict):\n",
    "    batch = producer.create_batch()             # Create an optimized batch container\n",
    "    batch.add(EventData(json.dumps(event)))     # Serialize dict → JSON → EventData\n",
    "    producer.send_batch(batch)                  # Publish the batch to Event Hub\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Helper: unified API response handling\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()                  # Return parsed JSON on success\n",
    "    return { \"error\": f\"{response.status_code}: {response.text}\" }\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Weather API wrappers: current, forecast, alerts\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    url = f\"{base_url}/current.json\"\n",
    "    params = {'key': api_key, 'q': location, 'aqi': 'yes'}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    url = f\"{base_url}/forecast.json\"\n",
    "    params = {'key': api_key, 'q': location, 'days': days}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    url = f\"{base_url}/alerts.json\"\n",
    "    params = {'key': api_key, 'q': location, 'alerts': 'yes'}\n",
    "    return handle_response(requests.get(url, params=params))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Flatten and merge API responses into one clean dict\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def flatten_data(current, forecast, alerts):\n",
    "    loc = current.get(\"location\", {})\n",
    "    cur = current.get(\"current\", {})\n",
    "    cond = cur.get(\"condition\", {})\n",
    "    aqi = cur.get(\"air_quality\", {})\n",
    "    days = forecast.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    al = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    return {\n",
    "        # Basic location info\n",
    "        \"name\": loc.get(\"name\"),\n",
    "        \"region\": loc.get(\"region\"),\n",
    "        \"country\": loc.get(\"country\"),\n",
    "\n",
    "        # Current conditions\n",
    "        \"temp_c\": cur.get(\"temp_c\"),\n",
    "        \"condition\": cond.get(\"text\"),\n",
    "\n",
    "        # Air quality readings\n",
    "        \"air_quality\": {k: aqi.get(k) for k in aqi},\n",
    "\n",
    "        # Next 3-day forecast\n",
    "        \"forecast\": [\n",
    "            {\n",
    "                \"date\": d.get(\"date\"),\n",
    "                \"max_temp\": d.get(\"day\", {}).get(\"maxtemp_c\"),\n",
    "                \"min_temp\": d.get(\"day\", {}).get(\"mintemp_c\"),\n",
    "                \"condition\": d.get(\"day\", {}).get(\"condition\", {}).get(\"text\")\n",
    "            } for d in days\n",
    "        ],\n",
    "\n",
    "        # Active weather alerts\n",
    "        \"alerts\": [\n",
    "            {\n",
    "                \"headline\": x.get(\"headline\"),\n",
    "                \"severity\": x.get(\"severity\"),\n",
    "                \"description\": x.get(\"desc\")\n",
    "            } for x in al\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Fetch + flatten all weather data\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1\"\n",
    "    location = \"Kolkata\"  # Change as needed\n",
    "    curr    = get_current_weather(base_url, weather_api_key, location)\n",
    "    forecast= get_forecast_weather(base_url, weather_api_key, location, days=3)\n",
    "    alrt    = get_alerts(base_url, weather_api_key, location)\n",
    "    return flatten_data(curr, forecast, alrt)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 9) Throttle control: track when last event was sent\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "last_sent_time = datetime.now() - timedelta(seconds=30)  # Ensure immediate first send\n",
    "#Suppose you run the code at 1:00 a.m, then the value for the variable would be 12:59:30 a.m.\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 10) Batch processor invoked by Spark Structured Streaming\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def process_batch(batch_df, batch_id):\n",
    "    \"\"\"\n",
    "    process_batch(batch_df, batch_id)\n",
    "    Purpose: Every time Spark’s streaming “heartbeat” fires (once per batch), this function runs—and only actually sends weather data if at least 30 seconds have passed since the last send.\n",
    "\n",
    "    batch_df\n",
    "    A mini-DataFrame of whatever rows Spark just received. In our test we’re using the built-in “rate” source (one dummy row per second). We don’t use its contents—we just need it to trigger our function.\n",
    "\n",
    "    batch_id\n",
    "    A simple counter (0, 1, 2, …) Spark assigns to each batch. Handy for logging or troubleshooting if something goes wrong.\n",
    "    \"\"\"\n",
    "\n",
    "    global last_sent_time\n",
    "    #why global variable? so that it can be used in another function (in this case process batch)\n",
    "    now = datetime.now()                                # Current timestamp\n",
    "    elapsed = (now - last_sent_time).total_seconds()    # Seconds since last send\n",
    "\n",
    "    if elapsed >= 30:\n",
    "    \"\"\"\n",
    "    We check how many seconds have passed since our last successful send. If it’s 30 seconds or more, we proceed; otherwise we skip this batch.\n",
    "    \"\"\"\n",
    "        try:\n",
    "            data = fetch_weather_data()  # Retrieve latest weather snapshot\n",
    "            send_event(data)             # Publish to Event Hub\n",
    "            \"\"\"\n",
    "            Trigger: Whenever Spark adds a new row to streaming_df, it bundles that row into the micro-batch and calls this function.\n",
    "\n",
    "            We ignore batch_df’s contents; instead we treat its arrival as a signal to call the weather API.\n",
    "            \"\"\"\n",
    "\n",
    "            last_sent_time = now         # Update throttle timestamp\n",
    "            print(f\"Event sent at {now.isoformat()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_id}: {e}\")\n",
    "            raise\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 11) Define a dummy streaming source to trigger batches\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "streaming_df = (\n",
    "    spark.readStream\n",
    "         .format(\"rate\")               # Generates rows at a fixed rate\n",
    "         .option(\"rowsPerSecond\", 1)   # One row per second\n",
    "         .load()\n",
    ")\n",
    "\"\"\"\n",
    "Rate source: emits exactly one fake row per second.\n",
    "Since weather API is not a streaming datasource, we cannot directly stream data from it, its just an API. We are using rate to emit it as a streaming source.\n",
    "Using rate means no external dependency; we generate “rows” purely to drive our logic.\n",
    "\"\"\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 12) Attach processor to the stream and start\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "query = (\n",
    "    streaming_df.writeStream\n",
    "               .foreachBatch(process_batch)  # Call our function each batch\n",
    "               .start()\n",
    ")\n",
    "\"\"\"\n",
    "writeStream: begins defining how to output the stream.\n",
    ".foreachBatch(process_batch): tells Spark “for each micro-batch, call process_batch(batch_df, batch_id).”\n",
    ".start(): kicks off the continuous streaming job.\n",
    "\"\"\"\n",
    "\n",
    "# Await termination (runs until manually stopped)\n",
    "query.awaitTermination()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 13) Cleanup: close the Event Hub producer when done\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "producer.close()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Weather Streaming Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

